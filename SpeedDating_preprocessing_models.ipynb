{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import datetime\n",
    "ts = '{:%Y%m%d%H%M%S}'.format(datetime.datetime.now())\n",
    "from IPython.display import Image\n",
    "from time import sleep\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from pandas import DataFrame, Series\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, f1_score\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'age', 'age_o', 'd_age', 'samerace', 'same_race_i',\n",
       "       'same_religion_i', 'attractive_o_i', 'sincere_o_i', 'intelligence_o_i',\n",
       "       ...\n",
       "       'gaming_n', 'clubbing_n', 'reading_n', 'tv_n', 'theater_n', 'movies_n',\n",
       "       'concerts_n', 'music_n', 'shopping_n', 'yoga_n'],\n",
       "      dtype='object', length=382)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8220, 293)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>age</th>\n",
       "      <th>age_o</th>\n",
       "      <th>d_age</th>\n",
       "      <th>samerace</th>\n",
       "      <th>same_race_i</th>\n",
       "      <th>same_religion_i</th>\n",
       "      <th>attractive_o_i</th>\n",
       "      <th>sincere_o_i</th>\n",
       "      <th>intelligence_o_i</th>\n",
       "      <th>...</th>\n",
       "      <th>field_tc [health ed]</th>\n",
       "      <th>field_teaching of english</th>\n",
       "      <th>field_tesol</th>\n",
       "      <th>field_theater</th>\n",
       "      <th>field_theatre management &amp; producing</th>\n",
       "      <th>field_theory</th>\n",
       "      <th>field_undergrad - gs</th>\n",
       "      <th>field_urban planning</th>\n",
       "      <th>field_working</th>\n",
       "      <th>field_writing: literary nonfiction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>21.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.19</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.15</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>21.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.20</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 293 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   age  age_o  d_age  samerace  same_race_i  same_religion_i  \\\n",
       "0           0  21.0   27.0      6         0          2.0              4.0   \n",
       "1           1  21.0   22.0      1         0          2.0              4.0   \n",
       "2           2  21.0   22.0      1         1          2.0              4.0   \n",
       "3           3  21.0   23.0      2         0          2.0              4.0   \n",
       "4           4  21.0   24.0      3         0          2.0              4.0   \n",
       "\n",
       "   attractive_o_i  sincere_o_i  intelligence_o_i  ...  field_tc [health ed]  \\\n",
       "0            0.35         0.20              0.20  ...                     0   \n",
       "1            0.60         0.00              0.00  ...                     0   \n",
       "2            0.19         0.18              0.19  ...                     0   \n",
       "3            0.30         0.05              0.15  ...                     0   \n",
       "4            0.30         0.10              0.20  ...                     0   \n",
       "\n",
       "   field_teaching of english  field_tesol  field_theater  \\\n",
       "0                          0            0              0   \n",
       "1                          0            0              0   \n",
       "2                          0            0              0   \n",
       "3                          0            0              0   \n",
       "4                          0            0              0   \n",
       "\n",
       "   field_theatre management & producing  field_theory  field_undergrad - gs  \\\n",
       "0                                     0             0                     0   \n",
       "1                                     0             0                     0   \n",
       "2                                     0             0                     0   \n",
       "3                                     0             0                     0   \n",
       "4                                     0             0                     0   \n",
       "\n",
       "   field_urban planning  field_working  field_writing: literary nonfiction  \n",
       "0                     0              0                                   0  \n",
       "1                     0              0                                   0  \n",
       "2                     0              0                                   0  \n",
       "3                     0              0                                   0  \n",
       "4                     0              0                                   0  \n",
       "\n",
       "[5 rows x 293 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"Speed_Dating_Clean.csv\")\n",
    "x = ['gender', 'race', 'race_o', 'field']\n",
    "columns = list(data)\n",
    "\n",
    "# Deleting bins\n",
    "for column in columns:\n",
    "    if column not in x and data[str(column)].dtype.name == 'object':\n",
    "        del data[str(column)]\n",
    "\n",
    "# Deleting useless columns        \n",
    "# del data['has_null']\n",
    "# del data['wave']\n",
    "# del data['d_age']\n",
    "# del data['samerace']\n",
    "# del data['expected_happy_with_sd_people']\n",
    "# del data['expected_num_interested_in_me']\n",
    "# del data['expected_num_matches']\n",
    "# del data['like']\n",
    "# del data['guess_prob_liked']\n",
    "del data['decision']\n",
    "del data['decision_o']\n",
    "\n",
    "# Replace age NA with mean\n",
    "mean = round(data['age'].mean())\n",
    "data['age'].fillna(mean, inplace = True)\n",
    "mean = round(data['age_o'].mean())\n",
    "data['age_o'].fillna(mean, inplace = True)\n",
    "\n",
    "# Make sure difference in age is correct\n",
    "data['age_d'] = (data['age'] - data['age_o'])\n",
    "data['age_d_abs'] = data['age_d'].abs()\n",
    "\n",
    "# Replace race NA with other\n",
    "data['race'].fillna('other', inplace= True)\n",
    "data['race_o'].fillna('other', inplace = True)\n",
    "\n",
    "# Verifying that same_race is correct with replaced race\n",
    "data['same_race'] = (data['race'] == data['race_o'])\n",
    "\n",
    "# Replace NA with 0 for preferences\n",
    "preferences = ['pref_o_attractive', 'pref_o_sincere', 'pref_o_intelligence', 'pref_o_funny', 'pref_o_ambitious', 'pref_o_shared_interests']          \n",
    "for pref in preferences:\n",
    "    data[pref].fillna(0, inplace = True)\n",
    "\n",
    "# Renaming column names\n",
    "data.rename(columns = {'importance_same_race':'same_race_i',\n",
    "                       'importance_same_religion': 'same_religion_i',\n",
    "                       'pref_o_attractive':'attractive_o_i',\n",
    "                       'pref_o_sincere':'sincere_o_i',\n",
    "                       'pref_o_intelligence':'intelligence_o_i',\n",
    "                       'pref_o_funny':'funny_o_i',\n",
    "                       'pref_o_ambitious':'ambitious_o_i',\n",
    "                       'pref_o_shared_interests':'shared_interests_o_i',\n",
    "                       'attractive_important':'attractive_i',\n",
    "                       'sincere_important': 'sincere_i',\n",
    "                       'intellicence_important': 'intelligence_i',\n",
    "                       'funny_important':'funny_i',\n",
    "                       'ambtition_important':'ambitious_i',\n",
    "                       'shared_interests_important':'shared_interests_i',\n",
    "                       'ambition':'ambitious',\n",
    "                       'sinsere_o': 'sincere_o',\n",
    "                       'ambitous_o':'ambitious_o',\n",
    "                       'ambition_partner':'ambitious_partner'}, inplace = True)\n",
    "\n",
    "# Making sure that opposite's importance columns add up to 100\n",
    "data['o_i'] = data['attractive_o_i'] + data['sincere_o_i'] + data['intelligence_o_i'] + data['funny_o_i'] + data['ambitious_o_i'] + data['shared_interests_o_i']\n",
    "data['attractive_o_i'] = (data['attractive_o_i'] / data['o_i'])\n",
    "data['sincere_o_i'] = (data['sincere_o_i'] / data['o_i'])\n",
    "data['intelligence_o_i'] = (data['intelligence_o_i'] / data['o_i'])\n",
    "data['funny_o_i'] = (data['funny_o_i'] / data['o_i'])\n",
    "data['ambitious_o_i'] = (data['ambitious_o_i'] / data['o_i'])\n",
    "data['shared_interests_o_i'] = (data['shared_interests_o_i'] / data['o_i'])\n",
    "\n",
    "# Making sure that my importance columns add up to 100\n",
    "data['i'] = data['attractive_i'] + data['sincere_i'] + data['intelligence_i'] + data['funny_i'] + data['ambitious_i'] + data['shared_interests_i']\n",
    "data['attractive_i'] = (data['attractive_i'] / data['i'])\n",
    "data['sincere_i'] = (data['sincere_i'] / data['i'])\n",
    "data['intelligence_i'] = (data['intelligence_i'] / data['i'])\n",
    "data['funny_i'] = (data['funny_i'] / data['i'])\n",
    "data['ambitious_i'] = (data['ambitious_i'] / data['i'])\n",
    "data['shared_interests_i'] = (data['shared_interests_i'] / data['i'])\n",
    "\n",
    "del data['o_i']\n",
    "del data['i']\n",
    "\n",
    "# Filling in data that are empty\n",
    "temp = ['attractive_o_i', 'sincere_o_i', 'intelligence_o_i', 'funny_o_i', 'ambitious_o_i', 'shared_interests_o_i', 'attractive_i', 'sincere_i', 'intelligence_i', 'funny_i', 'ambitious_i', 'shared_interests_i']          \n",
    "for t in temp:\n",
    "    data[t].fillna((1.0 / 6.0), inplace = True)\n",
    "\n",
    "# Replacing same_race_i & same_religion_i with mean (importance)\n",
    "mean = data['same_race_i'].mean()\n",
    "data['same_race_i'].fillna(round(mean), inplace = True)\n",
    "\n",
    "mean = data['same_religion_i'].mean()\n",
    "data['same_religion_i'].fillna(round(mean), inplace = True)\n",
    "\n",
    "# One Hot Encoding of categorical data\n",
    "data = pd.concat([data, pd.get_dummies(data['gender'], prefix = 'gender')], axis = 1)\n",
    "data = pd.concat([data, pd.get_dummies(data['race'], prefix = 'race')], axis = 1)\n",
    "data = pd.concat([data, pd.get_dummies(data['race_o'], prefix = 'race_o')], axis = 1)\n",
    "data = pd.concat([data, pd.get_dummies(data['field'], prefix = 'field')], axis = 1)\n",
    "\n",
    "del data['gender']\n",
    "del data['race']\n",
    "del data['race_o']\n",
    "del data['field']\n",
    "\n",
    "# Label Encoding\n",
    "le = LabelEncoder()\n",
    "data['same_race'] = le.fit_transform(data['same_race'])\n",
    "\n",
    "# Fill NA's with mean\n",
    "mean = data['attractive_o'].mean()\n",
    "data['attractive_o'].fillna(round(mean), inplace = True)\n",
    "mean = data['sincere_o'].mean()\n",
    "data['sincere_o'].fillna(round(mean), inplace = True)\n",
    "mean = data['intelligence_o'].mean()\n",
    "data['intelligence_o'].fillna(round(mean), inplace = True)\n",
    "mean = data['funny_o'].mean()\n",
    "data['funny_o'].fillna(round(mean), inplace = True)\n",
    "mean = data['ambitious_o'].mean()\n",
    "data['ambitious_o'].fillna(round(mean), inplace = True)\n",
    "mean = data['shared_interests_o'].mean()\n",
    "data['shared_interests_o'].fillna(round(mean), inplace = True)\n",
    "mean = data['attractive'].mean()\n",
    "data['attractive'].fillna(round(mean), inplace = True)\n",
    "mean = data['sincere'].mean()\n",
    "data['sincere'].fillna(round(mean), inplace = True)\n",
    "mean = data['intelligence'].mean()\n",
    "data['intelligence'].fillna(round(mean), inplace = True)\n",
    "mean = data['funny'].mean()\n",
    "data['funny'].fillna(round(mean), inplace = True)\n",
    "mean = data['ambitious'].mean()\n",
    "data['ambitious'].fillna(round(mean), inplace = True)\n",
    "mean = data['attractive_partner'].mean()\n",
    "data['attractive_partner'].fillna(round(mean), inplace = True)\n",
    "mean = data['sincere_partner'].mean()\n",
    "data['sincere_partner'].fillna(round(mean), inplace = True)\n",
    "mean = data['intelligence_partner'].mean()\n",
    "data['intelligence_partner'].fillna(round(mean), inplace = True)\n",
    "mean = data['funny_partner'].mean()\n",
    "data['funny_partner'].fillna(round(mean), inplace = True)\n",
    "mean = data['ambitious_partner'].mean()\n",
    "data['ambitious_partner'].fillna(round(mean), inplace = True)\n",
    "mean = data['shared_interests_partner'].mean()\n",
    "data['shared_interests_partner'].fillna(round(mean), inplace = True)\n",
    "mean = data['met'].mean()\n",
    "data['met'].fillna(round(mean), inplace = True)\n",
    "\n",
    "# Delete rows with NA's for interests correlate\n",
    "data = data.dropna(axis = 0, subset = ['interests_correlate'])\n",
    "\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Difference between opposite's and my importance\n",
    "data['attractive_i_d'] = (data['attractive_i'] - data['attractive_o_i'])\n",
    "data['sincere_i_d'] = (data['sincere_i'] - data['sincere_o_i'])\n",
    "data['intelligence_i_d'] = (data['intelligence_i'] - data['intelligence_o_i'])\n",
    "data['funny_i_d'] = (data['funny_i'] - data['funny_o_i'])\n",
    "data['ambitious_i_d'] = (data['ambitious_i'] - data['ambitious_o_i'])\n",
    "data['shared_interests_i_d'] = (data['shared_interests_i'] - data['shared_interests_o_i'])\n",
    "\n",
    "# Absolute difference of importance\n",
    "data['attractive_i_d_abs'] = data['attractive_i_d'].abs()\n",
    "data['sincere_i_d_abs'] = data['sincere_i_d'].abs()\n",
    "data['intelligence_i_d_abs'] = data['intelligence_i_d'].abs()\n",
    "data['funny_i_d_abs'] = data['funny_i_d'].abs()\n",
    "data['ambitious_i_d_abs'] = data['ambitious_i_d'].abs()\n",
    "data['shared_interests_i_d_abs'] = data['shared_interests_i_d'].abs()\n",
    "\n",
    "# Difference between opposite's and my rating of me\n",
    "data['attractive_d'] = (data['attractive'] - data['attractive_o'])\n",
    "data['sincere_d'] = (data['sincere'] - data['sincere_o'])\n",
    "data['intelligence_d'] = (data['intelligence'] - data['intelligence_o'])\n",
    "data['funny_d'] = (data['funny'] - data['funny_o'])\n",
    "data['ambitious_d'] = (data['ambitious'] - data['ambitious_o'])\n",
    "data['shared_interests_d'] = (data['shared_interests_partner'] - data['shared_interests_o'])\n",
    "\n",
    "# Absolute difference of rating\n",
    "data['attractive_d_abs'] = data['attractive_d'].abs()\n",
    "data['sincere_d_abs'] = data['sincere_d'].abs()\n",
    "data['intelligence_d_abs'] = data['intelligence_d'].abs()\n",
    "data['funny_d_abs'] = data['funny_d'].abs()\n",
    "data['ambitious_d_abs'] = data['ambitious_d'].abs()\n",
    "data['shared_interests_d_abs'] = data['shared_interests_d'].abs()\n",
    "\n",
    "# Changing from [1-10] scale to percentage for opposite's rating\n",
    "data['o'] = data['attractive_o'] + data['sincere_o'] + data['intelligence_o'] + data['funny_o'] + data['ambitious_o'] + data['shared_interests_o']\n",
    "data['attractive_o_n'] = (data['attractive_o'] / data['o'])\n",
    "data['sincere_o_n'] = (data['sincere_o'] / data['o'])\n",
    "data['intelligence_o_n'] = (data['intelligence_o'] / data['o'])\n",
    "data['funny_o_n'] = (data['funny_o'] / data['o'])\n",
    "data['ambitious_o_n'] = (data['ambitious_o'] / data['o'])\n",
    "data['shared_interests_o_n'] = (data['shared_interests_o'] / data['o'])\n",
    "\n",
    "# Changing from [1-10] scale to percentage for my rating of opposite\n",
    "data['p'] = data['attractive_partner'] + data['sincere_partner'] + data['intelligence_partner'] + data['funny_partner'] + data['ambitious_partner'] + data['shared_interests_partner']\n",
    "data['attractive_p_n'] = (data['attractive_partner'] / data['p'])\n",
    "data['sincere_p_n'] = (data['sincere_partner'] / data['p'])\n",
    "data['intelligence_p_n'] = (data['intelligence_partner'] / data['p'])\n",
    "data['funny_p_n'] = (data['funny_partner'] / data['p'])\n",
    "data['ambitious_p_n'] = (data['ambitious_partner'] / data['p'])\n",
    "data['shared_interests_p_n'] = (data['shared_interests_partner'] / data['p'])\n",
    "\n",
    "del data['o']\n",
    "del data['p']\n",
    "\n",
    "# Filling in blanks with 0\n",
    "preferences = ['attractive_o_n', 'sincere_o_n', 'intelligence_o_n', 'funny_o_n', 'ambitious_o_n', 'shared_interests_o_n', 'attractive_p_n', 'sincere_p_n', 'intelligence_p_n', 'funny_p_n', 'ambitious_p_n', 'shared_interests_p_n']\n",
    "for pref in preferences:\n",
    "    data[pref].fillna(0, inplace = True)\n",
    "\n",
    "# Difference of rating percentage\n",
    "data['d'] = data['attractive_d_abs'] + data['sincere_d_abs'] + data['intelligence_d_abs'] + data['funny_d_abs'] + data['ambitious_d_abs'] + data['shared_interests_d_abs']\n",
    "data['attractive_d_n'] = (data['attractive_d'] / data['d'])\n",
    "data['sincere_d_n'] = (data['sincere_d'] / data['d'])\n",
    "data['intelligence_d_n'] = (data['intelligence_d'] / data['d'])\n",
    "data['funny_d_n'] = (data['funny_d'] / data['d'])\n",
    "data['ambitious_d_n'] = (data['ambitious_d'] / data['d'])\n",
    "data['shared_interests_d_n'] = (data['shared_interests_d'] / data['d'])\n",
    "\n",
    "del data['d']\n",
    "\n",
    "# Absolute difference of rating percentage\n",
    "data['attractive_d_n_abs'] = data['attractive_d_n'].abs()\n",
    "data['sincere_d_n_abs'] = data['sincere_d_n'].abs()\n",
    "data['intelligence_d_n_abs'] = data['intelligence_d_n'].abs()\n",
    "data['funny_d_n_abs'] = data['funny_d_n'].abs()\n",
    "data['ambitious_d_n_abs'] = data['ambitious_d_n'].abs()\n",
    "data['shared_interests_d_n_abs'] = data['shared_interests_d_n'].abs()\n",
    "\n",
    "# Difference between opposite's importance and their rating of me\n",
    "data['attractive_oi_o_d_n'] = (data['attractive_o_i'] - data['attractive_o_n'])\n",
    "data['sincere_oi_o_d_n'] = (data['sincere_o_i'] - data['sincere_o_n'])\n",
    "data['intelligence_oi_o_d_n'] = (data['intelligence_o_i'] - data['intelligence_o_n'])\n",
    "data['funny_oi_o_d_n'] = (data['funny_o_i'] - data['funny_o_n'])\n",
    "data['ambitious_oi_o_d_n'] = (data['ambitious_o_i'] - data['ambitious_o_n'])\n",
    "data['shared_interests_oi_o_d_n'] = (data['shared_interests_o_i'] - data['shared_interests_o_n'])\n",
    "\n",
    "# Absolute difference of opposite's importance and their rating of me\n",
    "data['attractive_oi_o_d_n_abs'] = data['attractive_oi_o_d_n'].abs()\n",
    "data['sincere_oi_o_d_n_abs'] = data['sincere_oi_o_d_n'].abs()\n",
    "data['intelligence_oi_o_d_n_abs'] = data['intelligence_oi_o_d_n'].abs()\n",
    "data['funny_oi_o_d_n_abs'] = data['funny_oi_o_d_n'].abs()\n",
    "data['ambitious_oi_o_d_n_abs'] = data['ambitious_oi_o_d_n'].abs()\n",
    "data['shared_interests_oi_o_d_n_abs'] = data['shared_interests_oi_o_d_n'].abs()\n",
    "\n",
    "# Difference between my importance and my rating of opposite\n",
    "data['attractive_i_p_d_n'] = (data['attractive_i'] - data['attractive_p_n'])\n",
    "data['sincere_i_p_d_n'] = (data['sincere_i'] - data['sincere_p_n'])\n",
    "data['intelligence_i_p_d_n'] = (data['intelligence_i'] - data['intelligence_p_n'])\n",
    "data['funny_i_p_d_n'] = (data['funny_i'] - data['funny_p_n'])\n",
    "data['ambitious_i_p_d_n'] = (data['ambitious_i'] - data['ambitious_p_n'])\n",
    "data['shared_interests_i_p_d_n'] = (data['shared_interests_i'] - data['shared_interests_p_n'])\n",
    "\n",
    "# Absolute difference of my importance and my rating of opposite\n",
    "data['attractive_i_p_d_n_abs'] = data['attractive_i_p_d_n'].abs()\n",
    "data['sincere_i_p_d_n_abs'] = data['sincere_i_p_d_n'].abs()\n",
    "data['intelligence_i_p_d_n_abs'] = data['intelligence_i_p_d_n'].abs()\n",
    "data['funny_i_p_d_n_abs'] = data['funny_i_p_d_n'].abs()\n",
    "data['ambitious_i_p_d_n_abs'] = data['ambitious_i_p_d_n'].abs()\n",
    "data['shared_interests_i_p_d_n_abs'] = data['shared_interests_i_p_d_n'].abs()\n",
    "\n",
    "# Changing from [1-10] scale to percentage for activities\n",
    "data['a'] = data['sports'] + data['tvsports'] + data['exercise'] + data['dining'] + data['museums'] + data['art'] + data['hiking'] + data['gaming'] + data['clubbing'] + data['reading'] + data['tv'] + data['theater'] + data['movies'] + data['concerts'] + data['music'] + data['shopping'] + data['yoga']\n",
    "data['sports_n'] = (data['sports'] / data['a']) \n",
    "data['tvsports_n'] = (data['tvsports'] / data['a']) \n",
    "data['exercise_n'] = (data['exercise'] / data['a']) \n",
    "data['dining_n'] = (data['dining'] / data['a']) \n",
    "data['museums_n'] = (data['museums'] / data['a']) \n",
    "data['art_n'] = (data['art'] / data['a']) \n",
    "data['hiking_n'] = (data['hiking'] / data['a']) \n",
    "data['gaming_n'] = (data['gaming'] / data['a']) \n",
    "data['clubbing_n'] = (data['clubbing'] / data['a']) \n",
    "data['reading_n'] = (data['reading'] / data['a']) \n",
    "data['tv_n'] = (data['tv'] / data['a']) \n",
    "data['theater_n'] = (data['theater'] / data['a']) \n",
    "data['movies_n'] = (data['movies'] / data['a']) \n",
    "data['concerts_n'] = (data['concerts'] / data['a']) \n",
    "data['music_n'] = (data['music'] / data['a']) \n",
    "data['shopping_n'] = (data['shopping'] / data['a']) \n",
    "data['yoga_n'] = (data['yoga'] / data['a']) \n",
    "\n",
    "del data['a']\n",
    "\n",
    "#ata.to_csv('Speed_Dating_Clean_noSMOTE.csv', index = False)\n",
    "#data = data[data['match']==1]\n",
    "\n",
    "# Create train and test data for Darwin (no SMOTE)\n",
    "data_Y = data['match']\n",
    "data_X = data.drop(['match'], axis = 1)\n",
    "\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(data_X, data_Y, test_size = 0.20, random_state = 11)\n",
    "#train_data = pd.concat([train_X, train_Y], axis = 1)\n",
    "#train_data.to_csv('Speed_Dating_Clean_noSMOTE_train.csv', index = False)\n",
    "#test_data = pd.concat([test_X, test_Y], axis = 1)\n",
    "#test_data.to_csv('Speed_Dating_Clean_noSMOTE_test.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.to_csv('/Users/Aifaz/Desktop/FE_speed_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "ada = ADASYN(random_state=42)\n",
    "train_X, train_Y = ada.fit_resample(train_X, train_Y)\n",
    "#test_X,test_Y = ada.fit_resample(test_X,test_Y)\n",
    "#train_X, test_X, train_Y, test_Y = train_test_split(data_X, data_Y, test_size = 0.20, random_state = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(sampling_strategy = 'minority', random_state = 11)\n",
    "smote_X, smote_Y = sm.fit_sample(train_X, train_Y)\n",
    "test_X, test_Y = sm.fit_sample(test_X,test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 7s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
       "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=1, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                           n_iter_no_change=None, presort='deprecated',\n",
       "                           random_state=11, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0,\n",
       "                           warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "scaler = StandardScaler()\n",
    "pca = PCA(0.95, random_state = 11)\n",
    "clf = GradientBoostingClassifier(random_state = 11, n_estimators = 100)\n",
    "\n",
    "# Creating the pipeline\n",
    "pipe = Pipeline(steps = [('sca', scaler ), ('pca', pca), ('clf', clf)])\n",
    "\n",
    "# Pass the pipeline in to a cross_val_score \n",
    "#scores = cross_val_score(pipe, data_X, data_Y, cv = 5)\n",
    "\n",
    "clf.fit(train_X,train_Y)\n",
    "# Printing the average accuracy\n",
    "#print('Average Accuracy:', scores.mean() * 100)\n",
    "\n",
    "# Print classification report\n",
    "#pred_Y = cross_val_predict(pipe, data_X, data_Y, cv = 5)\n",
    "#print(\"\\n\", classification_report(test_Y, clf.predict(test_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9.32 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
       "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "              power_t=0.5, random_state=11, shuffle=True, solver='adam',\n",
       "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "scaler = StandardScaler()\n",
    "clf = MLPClassifier(random_state = 11)\n",
    "\n",
    "# Create pipeline\n",
    "pipe = Pipeline(steps = [('scaler', scaler), ('clf', clf)])\n",
    "\n",
    "# Set parameters\n",
    "param_grid = {\n",
    "    'clf__hidden_layer_sizes': [(50,), (60,), (70,), (80,), (90,), (100,)],\n",
    "    'clf__activation': ['identity', 'logistic', 'tanh', 'relu']\n",
    "}\n",
    "\n",
    "#grid_search = GridSearchCV(pipe, param_grid, iid = False, cv = 5)\n",
    "\n",
    "# Fit data and print results\n",
    "clf.fit(train_X, train_Y)\n",
    "#print(grid_search.best_params_)\n",
    "#print(\"Accuracy:\", grid_search.best_score_ * 100)\n",
    "\n",
    "# Print classification report\n",
    "#print(\"\\n\", classification_report(test_Y, clf.predict(test_X)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
